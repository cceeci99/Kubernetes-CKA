# get context name from kubeconfig file that has user = aws-user
1. kubectl config view --kubeconfig=my-kube-config -o jsonpath="{.contexts[?(@.context.user=='aws-user')].name}"

# get persistent volumes sorted by capacity and showing only NAME, CAPACITY columns
2. kubectl get pv --sort-by=.spec.capacity.storage -o=custom-columns=NAME:.metadata.name,CAPACITY:.spec.capacity.storage

# get nodes's osImage
3. kubectl get nodes -o jsonpath='{.items[*].status.nodeInfo.osImage}' 

# check all init container statuses of all pods in all namespaces
4. k get po -A -o jsonpath='{.items[*].status.initContainerStatuses[*].containerID}' | tr " " "\n"

## items[*] -> all pods
## initContainerStatuses[*] -> for each pod 
## tr " " "\n" -> is used to add newline between space

# get pods and resources they are using
5. kubectl get pods -o jsonpath=‘{range .items[*]} {“\n”} {.metadata.name} {.spec.containers[*].resources}’

# get pods and their image with custom columns named NAME, IMAGE
6. kubectl get pods -o custom-columns=METADATA:.metadata.name,IMAGE:.spec.containers[*].image

# get nodes that are schedulable (without any taints)
7. kubectl get nodes -o custom-columns=NODE:.metadata.name,TAINT:.spec.taints[*].effect | grep -v NoSchedule


### loop:  {range .items[*]} {...} {"\n"} {...} {end}
### condition:  [?(@. )]


search through json output
- kubectl get nodes -o json | jq -c 'paths' | grep -v "metadata"
